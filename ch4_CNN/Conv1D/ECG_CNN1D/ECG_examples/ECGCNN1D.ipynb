{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f29305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training size is  8528\n"
     ]
    }
   ],
   "source": [
    "# source:https://github.com/ismorphism/DeepECG\n",
    "# 2019/11/25    YANG Jie    小修改\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "number_of_classes = 4  # Total number of classes\n",
    "\n",
    "\n",
    "def to_one_hot(y):\n",
    "    return np_utils.to_categorical(y)\n",
    "\n",
    "\n",
    "def change(x):  # From boolean arrays to decimal arrays\n",
    "    answer = np.zeros((np.shape(x)[0]))\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        max_value = max(x[i, :])\n",
    "        max_index = list(x[i, :]).index(max_value)\n",
    "        answer[i] = max_index\n",
    "    return answer.astype(np.int)\n",
    "\n",
    "\n",
    "mypath = 'D:/pythonWS/DeepECG-master/training2017/'  # Training directory\n",
    "onlyfiles = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f[0] == 'A')]\n",
    "bats = [f for f in onlyfiles if f[7] == 'm']\n",
    "check = 100\n",
    "mats = [f for f in bats if (np.shape(sio.loadmat(mypath + f)['val'])[1] >= check)]\n",
    "size = len(mats)\n",
    "print('Total training size is ', size)\n",
    "big = 10100\n",
    "X = np.zeros((size, big))\n",
    "\n",
    "for i in range(size):\n",
    "    dummy = sio.loadmat(mypath + mats[i])['val'][0, :]\n",
    "    if (big - len(dummy)) <= 0:\n",
    "        X[i, :] = dummy[0:big]\n",
    "    else:\n",
    "        b = dummy[0:(big - len(dummy))]\n",
    "        goal = np.hstack((dummy, b))\n",
    "        while len(goal) != big:\n",
    "            b = dummy[0:(big - len(goal))]\n",
    "            goal = np.hstack((goal, b))\n",
    "        X[i, :] = goal\n",
    "\n",
    "target_train = np.zeros((size, 1))\n",
    "Train_data = pd.read_csv(mypath + 'REFERENCE.csv', sep=',', header=None, names=None)\n",
    "for i in range(size):\n",
    "    if Train_data.loc[Train_data[0] == mats[i][:6], 1].values == 'N':\n",
    "        target_train[i] = 0\n",
    "    elif Train_data.loc[Train_data[0] == mats[i][:6], 1].values == 'A':\n",
    "        target_train[i] = 1\n",
    "    elif Train_data.loc[Train_data[0] == mats[i][:6], 1].values == 'O':\n",
    "        target_train[i] = 2\n",
    "    else:\n",
    "        target_train[i] = 3\n",
    "\n",
    "Label_set = to_one_hot(target_train)\n",
    "\n",
    "X = (X - X.mean()) / (X.std())  # Some normalization here\n",
    "X = np.expand_dims(X, axis=2)  # For Keras's data input size\n",
    "\n",
    "values = [i for i in range(size)]\n",
    "permutations = np.random.permutation(values)\n",
    "X = X[permutations, :]\n",
    "Label_set = Label_set[permutations, :]\n",
    "\n",
    "train = 0.9  # Size of training set in percentage\n",
    "X_train = X[:int(train * size), :]\n",
    "Y_train = Label_set[:int(train * size), :]\n",
    "X_val = X[int(train * size):, :]\n",
    "Y_val = Label_set[int(train * size):, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c0def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 10046, 128)        7168      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1004, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1004, 128)         0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 980, 128)          409728    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 196, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 196, 128)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 187, 128)          163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 37, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 37, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 33, 128)           82048     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 737,348\n",
      "Trainable params: 737,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B275120C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B275120C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2753ACF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2753ACF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "30/30 - 187s - loss: 1.1509 - accuracy: 0.5513 - val_loss: 0.9435 - val_accuracy: 0.6190 - 187s/epoch - 6s/step\n",
      "Epoch 2/50\n",
      "30/30 - 190s - loss: 0.9997 - accuracy: 0.5889 - val_loss: 0.9081 - val_accuracy: 0.6190 - 190s/epoch - 6s/step\n",
      "Epoch 3/50\n",
      "30/30 - 187s - loss: 0.9262 - accuracy: 0.5888 - val_loss: 0.8547 - val_accuracy: 0.6190 - 187s/epoch - 6s/step\n",
      "Epoch 4/50\n",
      "30/30 - 185s - loss: 0.8714 - accuracy: 0.5924 - val_loss: 0.8024 - val_accuracy: 0.6506 - 185s/epoch - 6s/step\n",
      "Epoch 5/50\n",
      "30/30 - 181s - loss: 0.7948 - accuracy: 0.6536 - val_loss: 0.7221 - val_accuracy: 0.7186 - 181s/epoch - 6s/step\n",
      "Epoch 6/50\n",
      "30/30 - 182s - loss: 0.7710 - accuracy: 0.6767 - val_loss: 0.6826 - val_accuracy: 0.7210 - 182s/epoch - 6s/step\n",
      "Epoch 7/50\n",
      "30/30 - 180s - loss: 0.7114 - accuracy: 0.7029 - val_loss: 0.6427 - val_accuracy: 0.7468 - 180s/epoch - 6s/step\n",
      "Epoch 8/50\n",
      "30/30 - 181s - loss: 0.6627 - accuracy: 0.7253 - val_loss: 0.5876 - val_accuracy: 0.7608 - 181s/epoch - 6s/step\n",
      "Epoch 9/50\n",
      "30/30 - 181s - loss: 0.6309 - accuracy: 0.7375 - val_loss: 0.6021 - val_accuracy: 0.7585 - 181s/epoch - 6s/step\n",
      "Epoch 10/50\n",
      "30/30 - 182s - loss: 0.5998 - accuracy: 0.7506 - val_loss: 0.5478 - val_accuracy: 0.7984 - 182s/epoch - 6s/step\n",
      "Epoch 11/50\n",
      "30/30 - 185s - loss: 0.5774 - accuracy: 0.7698 - val_loss: 0.5265 - val_accuracy: 0.7984 - 185s/epoch - 6s/step\n",
      "Epoch 12/50\n",
      "30/30 - 183s - loss: 0.5641 - accuracy: 0.7798 - val_loss: 0.5012 - val_accuracy: 0.8218 - 183s/epoch - 6s/step\n",
      "Epoch 13/50\n",
      "30/30 - 193s - loss: 0.5531 - accuracy: 0.7808 - val_loss: 0.5267 - val_accuracy: 0.8171 - 193s/epoch - 6s/step\n",
      "Epoch 14/50\n",
      "30/30 - 186s - loss: 0.5389 - accuracy: 0.7945 - val_loss: 0.5064 - val_accuracy: 0.8312 - 186s/epoch - 6s/step\n",
      "Epoch 15/50\n",
      "30/30 - 189s - loss: 0.5108 - accuracy: 0.8052 - val_loss: 0.4771 - val_accuracy: 0.8324 - 189s/epoch - 6s/step\n",
      "Epoch 16/50\n",
      "30/30 - 189s - loss: 0.5009 - accuracy: 0.8141 - val_loss: 0.4648 - val_accuracy: 0.8288 - 189s/epoch - 6s/step\n",
      "Epoch 17/50\n",
      "30/30 - 185s - loss: 0.4976 - accuracy: 0.8182 - val_loss: 0.4723 - val_accuracy: 0.8511 - 185s/epoch - 6s/step\n",
      "Epoch 18/50\n",
      "30/30 - 189s - loss: 0.4969 - accuracy: 0.8203 - val_loss: 0.4483 - val_accuracy: 0.8441 - 189s/epoch - 6s/step\n",
      "Epoch 19/50\n",
      "30/30 - 188s - loss: 0.4767 - accuracy: 0.8210 - val_loss: 0.4506 - val_accuracy: 0.8453 - 188s/epoch - 6s/step\n",
      "Epoch 20/50\n",
      "30/30 - 198s - loss: 0.4760 - accuracy: 0.8189 - val_loss: 0.4651 - val_accuracy: 0.8382 - 198s/epoch - 7s/step\n",
      "Epoch 21/50\n",
      "30/30 - 198s - loss: 0.4632 - accuracy: 0.8259 - val_loss: 0.4660 - val_accuracy: 0.8288 - 198s/epoch - 7s/step\n",
      "Epoch 22/50\n",
      "30/30 - 196s - loss: 0.4501 - accuracy: 0.8323 - val_loss: 0.4531 - val_accuracy: 0.8406 - 196s/epoch - 7s/step\n",
      "Epoch 23/50\n",
      "30/30 - 194s - loss: 0.4587 - accuracy: 0.8369 - val_loss: 0.4580 - val_accuracy: 0.8370 - 194s/epoch - 6s/step\n",
      "Epoch 24/50\n",
      "30/30 - 193s - loss: 0.4462 - accuracy: 0.8383 - val_loss: 0.4443 - val_accuracy: 0.8464 - 193s/epoch - 6s/step\n",
      "Epoch 25/50\n",
      "30/30 - 193s - loss: 0.4343 - accuracy: 0.8426 - val_loss: 0.4623 - val_accuracy: 0.8453 - 193s/epoch - 6s/step\n",
      "Epoch 26/50\n",
      "30/30 - 194s - loss: 0.4282 - accuracy: 0.8438 - val_loss: 0.4476 - val_accuracy: 0.8535 - 194s/epoch - 6s/step\n",
      "Epoch 27/50\n",
      "30/30 - 195s - loss: 0.4370 - accuracy: 0.8434 - val_loss: 0.4785 - val_accuracy: 0.8488 - 195s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "30/30 - 195s - loss: 0.4183 - accuracy: 0.8491 - val_loss: 0.4641 - val_accuracy: 0.8499 - 195s/epoch - 6s/step\n",
      "Epoch 29/50\n",
      "30/30 - 177s - loss: 0.4252 - accuracy: 0.8490 - val_loss: 0.4518 - val_accuracy: 0.8406 - 177s/epoch - 6s/step\n",
      "Epoch 30/50\n",
      "30/30 - 180s - loss: 0.4177 - accuracy: 0.8479 - val_loss: 0.4725 - val_accuracy: 0.8417 - 180s/epoch - 6s/step\n",
      "Epoch 31/50\n",
      "30/30 - 181s - loss: 0.4186 - accuracy: 0.8455 - val_loss: 0.4465 - val_accuracy: 0.8558 - 181s/epoch - 6s/step\n",
      "Epoch 32/50\n",
      "30/30 - 178s - loss: 0.4119 - accuracy: 0.8517 - val_loss: 0.4438 - val_accuracy: 0.8593 - 178s/epoch - 6s/step\n",
      "Epoch 33/50\n",
      "30/30 - 183s - loss: 0.4040 - accuracy: 0.8511 - val_loss: 0.4562 - val_accuracy: 0.8558 - 183s/epoch - 6s/step\n",
      "Epoch 34/50\n",
      "30/30 - 181s - loss: 0.3994 - accuracy: 0.8556 - val_loss: 0.4299 - val_accuracy: 0.8581 - 181s/epoch - 6s/step\n",
      "Epoch 35/50\n",
      "30/30 - 180s - loss: 0.3939 - accuracy: 0.8565 - val_loss: 0.4255 - val_accuracy: 0.8617 - 180s/epoch - 6s/step\n",
      "Epoch 36/50\n",
      "30/30 - 184s - loss: 0.4113 - accuracy: 0.8554 - val_loss: 0.4627 - val_accuracy: 0.8441 - 184s/epoch - 6s/step\n",
      "Epoch 37/50\n",
      "30/30 - 179s - loss: 0.3849 - accuracy: 0.8619 - val_loss: 0.4552 - val_accuracy: 0.8511 - 179s/epoch - 6s/step\n",
      "Epoch 38/50\n",
      "30/30 - 185s - loss: 0.3808 - accuracy: 0.8621 - val_loss: 0.4577 - val_accuracy: 0.8453 - 185s/epoch - 6s/step\n",
      "Epoch 39/50\n",
      "30/30 - 180s - loss: 0.3742 - accuracy: 0.8628 - val_loss: 0.4430 - val_accuracy: 0.8570 - 180s/epoch - 6s/step\n",
      "Epoch 40/50\n",
      "30/30 - 181s - loss: 0.3799 - accuracy: 0.8625 - val_loss: 0.4294 - val_accuracy: 0.8617 - 181s/epoch - 6s/step\n",
      "Epoch 41/50\n",
      "30/30 - 180s - loss: 0.3873 - accuracy: 0.8610 - val_loss: 0.4502 - val_accuracy: 0.8558 - 180s/epoch - 6s/step\n",
      "Epoch 42/50\n",
      "30/30 - 181s - loss: 0.3608 - accuracy: 0.8694 - val_loss: 0.5078 - val_accuracy: 0.8546 - 181s/epoch - 6s/step\n",
      "Epoch 43/50\n",
      "30/30 - 182s - loss: 0.3567 - accuracy: 0.8658 - val_loss: 0.4659 - val_accuracy: 0.8476 - 182s/epoch - 6s/step\n",
      "Epoch 44/50\n",
      "30/30 - 181s - loss: 0.3686 - accuracy: 0.8633 - val_loss: 0.4851 - val_accuracy: 0.8535 - 181s/epoch - 6s/step\n",
      "Epoch 45/50\n",
      "30/30 - 179s - loss: 0.3545 - accuracy: 0.8747 - val_loss: 0.4599 - val_accuracy: 0.8593 - 179s/epoch - 6s/step\n",
      "Epoch 46/50\n",
      "30/30 - 180s - loss: 0.3693 - accuracy: 0.8623 - val_loss: 0.4988 - val_accuracy: 0.8511 - 180s/epoch - 6s/step\n",
      "Epoch 47/50\n",
      "30/30 - 181s - loss: 0.3559 - accuracy: 0.8721 - val_loss: 0.4647 - val_accuracy: 0.8476 - 181s/epoch - 6s/step\n",
      "Epoch 48/50\n",
      "30/30 - 183s - loss: 0.3559 - accuracy: 0.8688 - val_loss: 0.4383 - val_accuracy: 0.8464 - 183s/epoch - 6s/step\n",
      "Epoch 49/50\n",
      "30/30 - 183s - loss: 0.3544 - accuracy: 0.8731 - val_loss: 0.4677 - val_accuracy: 0.8535 - 183s/epoch - 6s/step\n",
      "Epoch 50/50\n",
      "30/30 - 197s - loss: 0.3445 - accuracy: 0.8736 - val_loss: 0.4729 - val_accuracy: 0.8617 - 197s/epoch - 7s/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Conv_models/History.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8996\\323466018.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Conv_models/History.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\downgrade\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3401\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3402\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3403\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3404\u001b[0m         )\n\u001b[0;32m   3405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\downgrade\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\downgrade\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         ) as handles:\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\downgrade\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m             )\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Conv_models/History.csv'"
     ]
    }
   ],
   "source": [
    "# def create_model():\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, 55, activation='relu', input_shape=(big, 1)))\n",
    "model.add(MaxPooling1D(10))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 25, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 10, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=256, epochs=50, verbose=2, shuffle=True)\n",
    "pd.DataFrame(hist.history).to_csv(path_or_buf='Conv_models/History.csv')\n",
    "predictions = model.predict(X_val)\n",
    "score = accuracy_score(change(Y_val), change(predictions))\n",
    "print('Last epoch\\'s validation score is ', score)\n",
    "df = pd.DataFrame(change(predictions))\n",
    "df.to_csv(path_or_buf='Conv_models/Preds_' + str(format(score, '.4f')) + '.csv', index=None, header=None)\n",
    "pd.DataFrame(confusion_matrix(change(Y_val), change(predictions))).to_csv(\n",
    "    path_or_buf='Conv_models/Result_Conf' + str(format(score, '.4f')) + '.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b837dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
